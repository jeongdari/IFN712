{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c625cfc9-70c4-4278-ac20-bc5d6125783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "file_path = 'Merged_GNSS_and_SNR_HKKT.csv'\n",
    "gnss_data = pd.read_csv(file_path)\n",
    "\n",
    "# Selecting relevant features for modeling\n",
    "features = ['Phase Residual (m)', 'STD of Pseudorange L1 (m)', 'STD of Pseudorange L2 (m)',\n",
    "            'Elevation (¡Æ)', 'Azimuth (¡Æ)', 'SNR(dBHz)', 'L1 MP(m)']\n",
    "\n",
    "# Drop rows with missing values in selected features\n",
    "gnss_data_clean = gnss_data.dropna(subset=features + ['Pseudorange Residual (m)'])\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = gnss_data_clean[features]\n",
    "y = gnss_data_clean['Pseudorange Residual (m)']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "413e5502-86bf-44df-b971-55eaf2ed6eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS of Original Pseudorange Residual (M_original): 0.9288 meters\n",
      "RMS after model prediction (M_m): 0.6378 meters\n",
      "Improvement Rate: 31.34%\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the pseudorange residual using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate RMS for M_original (y_test) and M_m (y_pred)\n",
    "a1 = np.sqrt(mean_squared_error(y_test, np.zeros_like(y_test)))  # RMS of original data\n",
    "a2 = np.sqrt(mean_squared_error(y_test, y_pred))  # RMS after model prediction\n",
    "\n",
    "# Calculate improvement rate\n",
    "improvement_rate = (a1 - a2) / a1\n",
    "\n",
    "# Print the results\n",
    "print(f'RMS of Original Pseudorange Residual (M_original): {a1:.4f} meters')\n",
    "print(f'RMS after model prediction (M_m): {a2:.4f} meters')\n",
    "print(f'Improvement Rate: {improvement_rate * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d4d937-995f-48ad-983c-e6473ad3b4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sklearn-env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 17325.0195\n",
      "Epoch 2/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 2205.5457\n",
      "Epoch 3/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 1732.5709\n",
      "Epoch 4/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203us/step - loss: 1008.2004\n",
      "Epoch 5/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 718.5107\n",
      "Epoch 6/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 398.9382\n",
      "Epoch 7/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 274.4516\n",
      "Epoch 8/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211us/step - loss: 381.2469\n",
      "Epoch 9/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199us/step - loss: 127.5898\n",
      "Epoch 10/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 82.5442\n",
      "Epoch 11/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 43.6967\n",
      "Epoch 12/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 59.7450\n",
      "Epoch 13/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 13.0544\n",
      "Epoch 14/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 37.7351\n",
      "Epoch 15/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 5.4760\n",
      "Epoch 16/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 1.7022\n",
      "Epoch 17/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210us/step - loss: 0.7462\n",
      "Epoch 18/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8687\n",
      "Epoch 19/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8615\n",
      "Epoch 20/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8710\n",
      "Epoch 21/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205us/step - loss: 0.8698\n",
      "Epoch 22/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 0.8713\n",
      "Epoch 23/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8692\n",
      "Epoch 24/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199us/step - loss: 0.8660\n",
      "Epoch 25/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203us/step - loss: 0.8650\n",
      "Epoch 26/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204us/step - loss: 0.8672\n",
      "Epoch 27/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203us/step - loss: 0.8694\n",
      "Epoch 28/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 0.8642\n",
      "Epoch 29/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211us/step - loss: 0.8638\n",
      "Epoch 30/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8657\n",
      "Epoch 31/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8667\n",
      "Epoch 32/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8677\n",
      "Epoch 33/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8631\n",
      "Epoch 34/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 0.8613\n",
      "Epoch 35/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8636\n",
      "Epoch 36/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 0.8643\n",
      "Epoch 37/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8646\n",
      "Epoch 38/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8667\n",
      "Epoch 39/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8660\n",
      "Epoch 40/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211us/step - loss: 0.8665\n",
      "Epoch 41/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 0.8675\n",
      "Epoch 42/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 0.8675\n",
      "Epoch 43/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 0.8661\n",
      "Epoch 44/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201us/step - loss: 0.8672\n",
      "Epoch 45/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8687\n",
      "Epoch 46/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8691\n",
      "Epoch 47/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8706\n",
      "Epoch 48/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199us/step - loss: 0.8671\n",
      "Epoch 49/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210us/step - loss: 0.8673\n",
      "Epoch 50/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200us/step - loss: 0.8686\n",
      "\u001b[1m2347/2347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "fcnn_model = Sequential()\n",
    "fcnn_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "fcnn_model.add(Dense(32, activation='relu'))\n",
    "fcnn_model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "fcnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "fcnn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# Predicting\n",
    "y_pred_fcnn = fcnn_model.predict(X_test)\n",
    "\n",
    "# Calculate RMS for FCNN\n",
    "a2_fcnn = np.sqrt(mean_squared_error(y_test, y_pred_fcnn))\n",
    "improvement_rate_fcnn = (a1 - a2_fcnn) / a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd98eb48-50de-40e2-9775-fa0b2f103a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCNN of Original Pseudorange Residual (M_original): 0.9288 meters\n",
      "FCNN after model prediction (M_m): 0.9278 meters\n",
      "Improvement Rate: 0.12%\n"
     ]
    }
   ],
   "source": [
    "print(f'FCNN of Original Pseudorange Residual (M_original): {a1:.4f} meters')\n",
    "print(f'FCNN after model prediction (M_m): {a2_fcnn:.4f} meters')\n",
    "print(f'Improvement Rate: {improvement_rate_fcnn * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847752ac-6920-44f2-a1f0-8987c3405aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_model = DecisionTreeRegressor()\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate RMS for Decision Tree\n",
    "a2_dt = np.sqrt(mean_squared_error(y_test, y_pred_dt))\n",
    "improvement_rate_dt = (a1 - a2_dt) / a1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff472bd3-95a2-4b82-bf8f-6ea3d0c4dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT of Original Pseudorange Residual (M_original): 0.9288 meters\n",
      "DT after model prediction (M_m): 0.6752 meters\n",
      "Improvement Rate: 27.31%\n"
     ]
    }
   ],
   "source": [
    "print(f'DT of Original Pseudorange Residual (M_original): {a1:.4f} meters')\n",
    "print(f'DT after model prediction (M_m): {a2_dt:.4f} meters')\n",
    "print(f'Improvement Rate: {improvement_rate_dt * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa279dc-5eb5-469f-8887-a6093525c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate RMS for Random Forest\n",
    "a2_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "improvement_rate_rf = (a1 - a2_rf) / a1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1223246-dd3b-4d29-a557-364d498329db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF of Original Pseudorange Residual (M_original): 0.9288 meters\n",
      "RF after model prediction (M_m): 0.4837 meters\n",
      "Improvement Rate: 47.92%\n"
     ]
    }
   ],
   "source": [
    "print(f'RF of Original Pseudorange Residual (M_original): {a1:.4f} meters')\n",
    "print(f'RF after model prediction (M_m): {a2_rf:.4f} meters')\n",
    "print(f'Improvement Rate: {improvement_rate_rf * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90447695-98f0-43c7-93f0-578684857e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sklearn-env/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 257us/step - loss: 185421.0156\n",
      "Epoch 2/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 3642.3652\n",
      "Epoch 3/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 271us/step - loss: 551.3106\n",
      "Epoch 4/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256us/step - loss: 241.6526\n",
      "Epoch 5/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255us/step - loss: 136.9399\n",
      "Epoch 6/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255us/step - loss: 25.3980\n",
      "Epoch 7/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255us/step - loss: 8.4746\n",
      "Epoch 8/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260us/step - loss: 2.5278\n",
      "Epoch 9/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 259us/step - loss: 1.1715\n",
      "Epoch 10/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257us/step - loss: 0.6436\n",
      "Epoch 11/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 274us/step - loss: 0.8705\n",
      "Epoch 12/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 259us/step - loss: 0.8675\n",
      "Epoch 13/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 263us/step - loss: 0.8611\n",
      "Epoch 14/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257us/step - loss: 0.8715\n",
      "Epoch 15/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256us/step - loss: 0.8663\n",
      "Epoch 16/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 267us/step - loss: 0.8660\n",
      "Epoch 17/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257us/step - loss: 0.8630\n",
      "Epoch 18/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256us/step - loss: 0.8668\n",
      "Epoch 19/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256us/step - loss: 0.8669\n",
      "Epoch 20/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8692\n",
      "Epoch 21/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8718\n",
      "Epoch 22/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8690\n",
      "Epoch 23/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 259us/step - loss: 0.8692\n",
      "Epoch 24/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255us/step - loss: 0.8725\n",
      "Epoch 25/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 255us/step - loss: 0.8650\n",
      "Epoch 26/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8670\n",
      "Epoch 27/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8646\n",
      "Epoch 28/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 268us/step - loss: 0.8619\n",
      "Epoch 29/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8724\n",
      "Epoch 30/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 259us/step - loss: 0.8642\n",
      "Epoch 31/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 262us/step - loss: 0.8667\n",
      "Epoch 32/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260us/step - loss: 0.8676\n",
      "Epoch 33/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256us/step - loss: 0.8709\n",
      "Epoch 34/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260us/step - loss: 0.8689\n",
      "Epoch 35/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8634\n",
      "Epoch 36/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8679\n",
      "Epoch 37/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 267us/step - loss: 0.8621\n",
      "Epoch 38/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257us/step - loss: 0.8659\n",
      "Epoch 39/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 257us/step - loss: 0.8679\n",
      "Epoch 40/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 258us/step - loss: 0.8667\n",
      "Epoch 41/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260us/step - loss: 0.8712\n",
      "Epoch 42/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 259us/step - loss: 0.8684\n",
      "Epoch 43/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 264us/step - loss: 0.8705\n",
      "Epoch 44/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 274us/step - loss: 0.8661\n",
      "Epoch 45/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260us/step - loss: 0.8660\n",
      "Epoch 46/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260us/step - loss: 0.8646\n",
      "Epoch 47/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260us/step - loss: 0.8675\n",
      "Epoch 48/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 256us/step - loss: 0.8689\n",
      "Epoch 49/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 260us/step - loss: 0.8679\n",
      "Epoch 50/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 271us/step - loss: 0.8641\n",
      "\u001b[1m2347/2347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense\n",
    "\n",
    "# Reshape the input data for CNN (assuming time-series type data)\n",
    "X_train_cnn = np.expand_dims(X_train, axis=2)\n",
    "X_test_cnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "# Define the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train_cnn.shape[1], 1)))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(32, activation='relu'))\n",
    "cnn_model.add(Dense(1))\n",
    "\n",
    "# Compile and train the CNN model\n",
    "cnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "cnn_model.fit(X_train_cnn, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Predicting\n",
    "y_pred_cnn = cnn_model.predict(X_test_cnn)\n",
    "\n",
    "# Calculate RMS for CNN\n",
    "a2_cnn = np.sqrt(mean_squared_error(y_test, y_pred_cnn))\n",
    "improvement_rate_cnn = (a1 - a2_cnn) / a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b7cd80-b5e4-4f11-b034-916ed32c79cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN of Original Pseudorange Residual (M_original): 0.9288 meters\n",
      "CNN after model prediction (M_m): 0.9277 meters\n",
      "Improvement Rate: 0.12%\n"
     ]
    }
   ],
   "source": [
    "print(f'CNN of Original Pseudorange Residual (M_original): {a1:.4f} meters')\n",
    "print(f'CNN after model prediction (M_m): {a2_cnn:.4f} meters')\n",
    "print(f'Improvement Rate: {improvement_rate_cnn * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96ad4806-e7c2-407b-b790-b07b9fc76859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sklearn-env/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.4075\n",
      "Epoch 2/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.3342\n",
      "Epoch 3/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.3285\n",
      "Epoch 4/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.3285\n",
      "Epoch 5/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.3210\n",
      "Epoch 6/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.3193\n",
      "Epoch 7/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.3156\n",
      "Epoch 8/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.3125\n",
      "Epoch 9/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.3081\n",
      "Epoch 10/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.3049\n",
      "Epoch 11/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.3025\n",
      "Epoch 12/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2991\n",
      "Epoch 13/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2946\n",
      "Epoch 14/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2935\n",
      "Epoch 15/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2903\n",
      "Epoch 16/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2859\n",
      "Epoch 17/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2806\n",
      "Epoch 18/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.2782\n",
      "Epoch 19/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2756\n",
      "Epoch 20/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2712\n",
      "Epoch 21/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2690\n",
      "Epoch 22/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.2681\n",
      "Epoch 23/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2652\n",
      "Epoch 24/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2619\n",
      "Epoch 25/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2634\n",
      "Epoch 26/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.2580\n",
      "Epoch 27/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.2582\n",
      "Epoch 28/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2559\n",
      "Epoch 29/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2557\n",
      "Epoch 30/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2522\n",
      "Epoch 31/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2527\n",
      "Epoch 32/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2617\n",
      "Epoch 33/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2521\n",
      "Epoch 34/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2485\n",
      "Epoch 35/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2540\n",
      "Epoch 36/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2452\n",
      "Epoch 37/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2443\n",
      "Epoch 38/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2430\n",
      "Epoch 39/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2402\n",
      "Epoch 40/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2408\n",
      "Epoch 41/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 0.2405\n",
      "Epoch 42/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2402\n",
      "Epoch 43/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2393\n",
      "Epoch 44/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 0.2388\n",
      "Epoch 45/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.2358\n",
      "Epoch 46/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2346\n",
      "Epoch 47/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 0.2336\n",
      "Epoch 48/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.2343\n",
      "Epoch 49/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.2333\n",
      "Epoch 50/50\n",
      "\u001b[1m9387/9387\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.2312\n",
      "\u001b[1m2347/2347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 609us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "# Reshape the input data for RNN (time-series data)\n",
    "X_train_rnn = np.expand_dims(X_train, axis=2)\n",
    "X_test_rnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "# Define the RNN (LSTM) model\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(50, return_sequences=True, input_shape=(X_train_rnn.shape[1], 1)))\n",
    "rnn_model.add(LSTM(50))\n",
    "rnn_model.add(Dense(1))\n",
    "\n",
    "# Compile and train the RNN model\n",
    "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "rnn_model.fit(X_train_rnn, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Predicting\n",
    "y_pred_rnn = rnn_model.predict(X_test_rnn)\n",
    "\n",
    "# Calculate RMS for RNN\n",
    "a2_rnn = np.sqrt(mean_squared_error(y_test, y_pred_rnn))\n",
    "improvement_rate_rnn = (a1 - a2_rnn) / a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bc7b89f-717a-49e4-9c38-e7f2019edf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN of Original Pseudorange Residual (M_original): 0.9288 meters\n",
      "RNN after model prediction (M_m): 0.4903 meters\n",
      "Improvement Rate: 47.21%\n"
     ]
    }
   ],
   "source": [
    "print(f'RNN of Original Pseudorange Residual (M_original): {a1:.4f} meters')\n",
    "print(f'RNN after model prediction (M_m): {a2_rnn:.4f} meters')\n",
    "print(f'Improvement Rate: {improvement_rate_rnn * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a6f695d-8909-4255-a52c-2ee4627c895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS of RBF SVR Model (Downsampled): 0.5641 meters\n",
      "Improvement Rate: 39.26%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "# Downsample the data (e.g., to 50% of the original data)\n",
    "X_train_downsampled, y_train_downsampled = resample(X_train, y_train, n_samples=int(len(X_train) * 0.5), random_state=42)\n",
    "\n",
    "# Scaling the downsampled data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_downsampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the SVR model with 'rbf' kernel\n",
    "svm_model_rbf = SVR(kernel='rbf', cache_size=200, tol=1e-3)  # You can also adjust tol and cache_size for performance\n",
    "svm_model_rbf.fit(X_train_scaled, y_train_downsampled)\n",
    "\n",
    "# Predicting\n",
    "y_pred_svm_rbf = svm_model_rbf.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMS for SVR with RBF kernel\n",
    "a2_svm_rbf = np.sqrt(mean_squared_error(y_test, y_pred_svm_rbf))\n",
    "improvement_rate_svm_rbf = (a1 - a2_svm_rbf) / a1\n",
    "\n",
    "print(f'RMS of RBF SVR Model (Downsampled): {a2_svm_rbf:.4f} meters')\n",
    "print(f'Improvement Rate: {improvement_rate_svm_rbf * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc54e3f-f9f4-48f1-9293-6efdee956003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "sklearn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
